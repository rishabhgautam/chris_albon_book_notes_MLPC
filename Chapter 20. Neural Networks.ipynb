{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.1 Preprocessing Data for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.12541308,  1.96429418],\n",
       "       [-1.15329466, -0.50068741],\n",
       "       [ 0.29529406, -0.22809346],\n",
       "       [ 0.57385917, -0.42335076],\n",
       "       [ 1.40955451, -0.81216255]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Create feature\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                     [-200.2, -234.1],\n",
    "                     [5000.5, 150.1],\n",
    "                     [6000.6, -125.1],\n",
    "                     [9000.9, -673.1]])\n",
    "\n",
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Transform the feature\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# Show feature\n",
    "features_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Standard deviation: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation\n",
    "print(\"Mean:\", round(features_standardized[:,0].mean()))\n",
    "print(\"Standard deviation:\", features_standardized[:,0].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.2 Designing a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(10,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.3 Training a Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4213 - accuracy: 0.8094 - val_loss: 0.3382 - val_accuracy: 0.8574\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.8621 - val_loss: 0.3408 - val_accuracy: 0.8547\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3159 - accuracy: 0.8679 - val_loss: 0.3274 - val_accuracy: 0.8588\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\n",
    "    number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=1, # Print description after each epoch\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.4 Training a Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 8s 4us/step\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 5000\n",
    "\n",
    "# Load feature and target data\n",
    "data = reuters.load_data(num_words=number_of_features)\n",
    "(data_train, target_vector_train), (data_test, target_vector_test) = data\n",
    "\n",
    "# Convert feature data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# One-hot encode target vector to create a target matrix\n",
    "target_train = to_categorical(target_vector_train)\n",
    "target_test = to_categorical(target_vector_test)\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=100, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(layers.Dense(units=46, activation=\"softmax\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target\n",
    "                      epochs=3, # Three epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.5 Training a Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                   n_features = 3,\n",
    "                                   n_informative = 3,\n",
    "                                   n_targets = 1,\n",
    "                                   noise = 0.0,\n",
    "                                   random_state = 0)\n",
    "\n",
    "# Divide our data into training and test sets\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=32,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(features_train.shape[1],)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=32, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with no activation function\n",
    "network.add(layers.Dense(units=1))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"mse\", # Mean squared error\n",
    "                optimizer=\"RMSprop\", # Optimization algorithm\n",
    "                metrics=[\"mse\"]) # Mean squared error\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=10, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.6 Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 10000\n",
    "\n",
    "# Load data and target vector from IMDB movie data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert IMDB data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data\n",
    "\n",
    "# Predict classes of test set\n",
    "predicted_target = network.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.7 Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 10000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target\n",
    "                      epochs=15, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=1000, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history[\"loss\"]\n",
    "test_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, \"r--\")\n",
    "plt.plot(epoch_count, test_loss, \"b-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3iUZdb48e9JAoQqoSglNBFdqQECylpRQVZdUVEBURFUBMW6+hNX1oK+iL66KhYUpVgwwIoFCyAitncVCCaIgBA6oUiTIkgJnN8f95NkkkySCWTyTJLzua7nmpmnzRnKnLm7qCrGGGNMqKL8DsAYY0zpYonDGGNMkVjiMMYYUySWOIwxxhSJJQ5jjDFFEuN3ACWhTp062rRpU7/DMMaYUmXhwoXbVbVu7v3lInE0bdqU5ORkv8MwxphSRUTWBdtvVVXGGGOKxBKHMcaYIrHEYYwxpkjKRRtHMIcPHyY9PZ0DBw74HYopIbGxscTHx1OhQgW/QzGmVCu3iSM9PZ3q1avTtGlTRMTvcEyYqSo7duwgPT2dZs2a+R2OMaVaua2qOnDgALVr17akUU6ICLVr17YSpjHFoNwmDsCSRjljf9/GFI+wJg4R6SEiy0VkpYgMC3K8iYjMEZGfReRrEYn39ncVkdSA7YCIXOEdmygiawKOJYTzMxhjTKly6BAsXgzvvgvLl4flLcKWOEQkGngF+BvQEugrIi1znfYs8LaqtgVGAE8BqOpcVU1Q1QTgAmA/8EXAdQ9kHlfV1HB9hnDasWMHCQkJJCQkUK9ePRo2bJj1+tChQyHdY8CAASwv5B/GK6+8wqRJk4ojZAB+++03YmJiGDduXLHd0xhzjH77DZYuzX597rlQrRq0bQs33ACffBKWtw1n43hnYKWqrgYQkclATyDgU9ISuNd7Phf4KMh9rgZmqOr+MMZa4mrXrk1qqst5jz32GNWqVeP+++/PcY6qoqpERQXP7xMmTCj0fe64447jDzbAlClT6NKlC0lJSdx8883Feu9AGRkZxMSU274bxgQ3fTp8+y0sWgQ//wxbt0JiIixY4I536gR//atLHO3awamnhiWMcFZVNQQ2BLxO9/YFWgT08p5fCVQXkdq5zukDJOXa9z9e9dbzIlKpuAKOBCtXrqR169YMHjyYDh06sHnzZgYNGkRiYiKtWrVixIgRWeeeffbZpKamkpGRQc2aNRk2bBjt2rWjS5cubN26FYDhw4fzwgsvZJ0/bNgwOnfuzGmnncZ///tfAPbt20evXr1o164dffv2JTExMSup5ZaUlMQLL7zA6tWr2bJlS9b+zz77jA4dOtCuXTu6d+8OwN69e+nfvz9t2rShbdu2fPTRR1mxZpo8eTK33HILANdffz3/+Mc/6Nq1K//85z/58ccf6dKlC+3bt+ess84iLS0NcEnl3nvvpXXr1rRt25ZXX32VWbNmcc0112Tdd8aMGVx77bXH/fdhTIlShc2bYeZMeOYZuP56uPDC7OPvvAMvvwy//w6XXgovvAD//nf28eeeg1Gj4LrroFUrCFPX83D+pAvWEpl7ndr7gZdF5CbgW2AjkJF1A5H6QBtgVsA1DwFbgIrAWOBBXDVXzjcXGQQMAmjcuHHh0Z5/ft59114Lt98O+/fDJZfkPX7TTW7bvh2uvjrnsa+/Lvw987F06VImTJjAa6+9BsCoUaOoVasWGRkZdO3alauvvpqWLXPW+u3evZvzzjuPUaNGcd999zF+/HiGDcvTrISqMn/+fKZPn86IESOYOXMmL730EvXq1WPatGksWrSIDh06BI1r7dq1/P7773Ts2JGrr76aqVOnctddd7FlyxaGDBnCd999R5MmTdi5cyfgSlJ169Zl8eLFqCq7du0q9LOvWrWKOXPmEBUVxe7du/n++++Jjo5m5syZDB8+nClTpjBmzBg2bdrEokWLiI6OZufOndSsWZO77rqLHTt2ULt2bSZMmMCAAQOK+kdvTMG2bYOVK+HwYcjIcNvhw+5XflwcrF4NP/yQvT/znL59oXZtVzKYOTPnsYwMGD4catWChx6Cp5/Ofr9GjVzp4eBBqFQJxo6F6tXB59J4ON89HWgU8Doe2BR4gqpuAq4CEJFqQC9V3R1wyrXAh6p6OOCazd7TgyIyAZd88lDVsbjEQmJiYqlaWL158+Z06tQp63VSUhLjxo0jIyODTZs2sXTp0jyJo3Llyvztb38DoGPHjnz33XdB733VVVdlnbN27VoAvv/+ex588EEA2rVrR6tWrYJem5SURO/evQHo06cPd9xxB3fddRc//PADXbt2pUmTJgDUqlULgC+//JKPPnK1jyJCXFwcGRkZQe+d6Zprrsmqmtu1axc33ngjq1atynHOl19+yT333EN0dHSO97vuuut477336NevHwsXLiQpKXdB1ZhC/PEHLFzoEsCaNdmPzz4LXbrAN99AQMk2y3ffwdlnw/ffQ//+eY+fc45LHPPnwyOPuH0xMa5EEBMDd93lEsdll0HDhi5ZtGnj9gWKiyv+z3wMwpk4FgAtRKQZriTRB7gu8AQRqQPsVNWjuJLE+Fz36OvtD7ymvqpuFte38grgl2KJtqASQpUqBR+vU+e4Shi5Va1aNet5WloaL774IvPnz6dmzZpcf/31QcciVKxYMet5dHR0vl/QlSpVynOOamh5NSkpiR07dvDWW28BsGnTJtasWYOqBu3qGmx/VFRUjvfL/VkCP/vDDz/MxRdfzO23387KlSvp0aNHvvcFGDhwIL16uZrP3r17ZyUWY7Jk9jgKTAqrV7uahZ49YcmS7NqHqCj3i//kk12pAKBrV1diiInJ+cV/+unueM+esGJF9vHMczKrZwcPdltUFATrHn722W6LcGFLHKqaISJDcdVM0cB4VV0iIiOAZFWdDpwPPCUiiquqymrJFZGmuBLLN7luPUlE6uKqwlKBweH6DJFgz549VK9enRo1arB582ZmzZqV9QVaXM4++2ymTp3KOeecw+LFi1ka2EvDs3TpUo4cOcLGjRuz9j388MNMnjyZgQMHcs8997Bu3bqsqqpatWrRvXt3Xn75ZZ599tmsqqq4uDji4uJIS0ujefPmfPjhh9Stm2e6f8BVvzVs6JrFJk6cmLW/e/fujBkzhnPOOSerqqpWrVo0atSIOnXqMGrUKObOnVusf0amlFB1yWDlSretWeO2Sy+FAQNctXJiYvb5tWq5xJDZk7F1a5g9G5o1g8aN87YR1K4NF1+c//ufcILb8lNGfsyEtaJMVT8HPs+175GA5+8D7+dz7VryNqajqhcUb5SRrUOHDrRs2ZLWrVtz8sknc9ZZZxX7e9x5553ceOONtG3blg4dOtC6dWtOyPWP/7333uPKK6/Msa9Xr17079+fhx56iDFjxtCzZ09UlQYNGjBjxgweffRRbr/9dlq3bk10dDRPPPEEl19+OU8//TQ9evSgcePGtGzZkoMHDwaN68EHH2TgwIE888wzdO3aNWv/bbfdRlpaGm3btiUmJoYhQ4YweLD7/XDdddexZ88eTg1TbxITATIyYN06lxjS0tzjaafBkCFw5Ih7nllCqFTJJYHMX/H16sG0aS5ZNGuW90u+alW46KKS/TylkIRaTVGaJSYmau6FnJYtW8bpmcXLci4jI4OMjAxiY2NJS0uje/fupKWllcrusIMHD6ZLly70D1bPjP29lxoZGbB2bXbJoWJFGDTIHWve3FUvZapa1fU+8jqTMHWqSxDNm0P9+q5ayBwTEVmoqom595e+bwZT7P744w8uvPBCMjIyUFVef/31Upk0EhISiIuLY/To0X6HYkK1ebMbk7BjB/Tr5/b16eNKBYHtdO3bZyeOhx5yVT6nnAItWsBJJ+VsL7Bu2GFX+r4dTLGrWbMmCxcu9DuM45bf2BMTYaZOddNhLFwIm7yOllWrurEHIm70c/PmLimccorbTjop+3pv3I/xjyUOY0zx27rVJYbkZPe4cKEb6RwXl90uccEFrqG6QwfXLpHp9tv9i9uExBKHMeb4bN/uEkP79nDiifD229ljGUTctBfnnefGSMTFwT//CQ8/7G/M5rhY4jDGFM3WrTBuXHZpYt06t//dd107xVlnuQFziYkumdSokfN6m96+1LPEYUx5dPiwm+8ocKtfHxIS3PQWDz2UvX/XLvc4YADcc4+79p//dG0PZ54JQ4dCx47Z4yOaN4d//MPfz2fCyhKHT3bs2MGF3uRlW7ZsITo6Omsg3Pz583OMBC/I+PHjueSSS6hXr17Q44cOHaJevXrccccdPPHEE8UTvIl8zz0HGzfmTAznnguZ/wZq1IDcMxAMGgSvv+4Gvb35phvjEBfntmbNXDUUQIMG7n4Bk1Wa8sUSh09CmVY9FOPHj6dDhw75Jo6ZM2fSsmVLpkyZEtbEYdOg+0TVTZPx2WeuDSHz7/iVV9yEfJlf/HFxULly9nUjR7qxEYHHG3lTy0VFwZ49+b+niCWNcs5GxkSgt956i86dO5OQkMDtt9/O0aNHycjI4IYbbqBNmza0bt2a0aNHM2XKFFJTU+ndu3e+C0AlJSVx3333cdJJJ7Egc85+YN68eXTp0oV27dpxxhlnsH///qDTlQPEx8dnzWz7448/cpE3snb48OHcdtttdOvWjQEDBrBq1SrOOecc2rdvT8eOHZk3b17W+40cOZI2bdrQrl07Hn74YZYvX07nzp2zji9btizHa1OI7793vY+aNnWT4Q0b5tZpyBzQm5YGe/fC+vVunMTXX7vqpUz33gt33OG6wP7tb67KqWGeiRqMCcp+IuKqbYt7CEBCgpsqv6h++eUXPvzwQ/773/8SExPDoEGDmDx5Ms2bN2f79u0sXrwYcDPH1qxZk5deeomXX36ZhIS8K+ju27ePb775hgkTJrBlyxaSkpLo1KkTBw4coE+fPkybNo0OHTqwe/duKlWqxKuvvppnuvLCpKSk8O233xIbG8v+/fuZPXs2sbGx/Prrr/Tv35958+bxySefMGPGDObPn0/lypWz5paKjY3ll19+oXXr1jYNemHWrYPPP3ftDLGxbqK9t99202MMH+6m/Q/84i8jcyKZyGSJI8J8+eWXLFiwgESvofHPP/+kUaNGXHzxxSxfvpy7776bSy65JGuxpIJMnz6dbt26ERsbyzXXXENiYiLPPvssy5Yto3HjxlnrbmTOS5XfdOUF6dmzJ7GxsQAcPHiQoUOHsmjRImJiYrKmQ//yyy8ZOHAglb2qksz73nzzzUyYMIGnn36a//znP6SkpBTlj6psy8hw6zp89pnbfvEmgT7tNDf+4f77XcLw/uyNKUmWODi2kkG4qCoDBw4M2h7x888/M2PGDEaPHs20adMYO3ZsgfdKSkpi3rx5NG3aFICtW7fy7bffUqNGjZCnQQeIiYnh6NGjQMHToD/33HM0atSId999l8OHD1OtWrUC73vNNdcwcuRIzjrrLLp06ZJjZcByaft216OpYUP46SfXmB0T49ZyePZZN8Nr5kC58v5nZXxlbRwR5qKLLmLq1Kls374dcL2v1q9fz7Zt21BVrrnmGh5//HF++uknAKpXr87evXvz3Of3339n3rx5pKens3btWtauXcvo0aNJSkqiVatWrFu3Lusee/bs4ciRI1nTlR85cgQgq6qqadOmWVOSTJs2Ld/Yd+/eTf369RER3nrrrax1N7p37864ceP4888/c9y3SpUqXHDBBQwdOrR8VlOputHUI0e6sQ8nneSeg+va+v77Lpl89ZXr3vqXv9gYCBMRLHFEmDZt2vDoo49y0UUX0bZtW7p3785vv/3Ghg0bOPfcc0lISODWW29lpPcFM2DAAG655ZY8jePTpk2jW7duVAhYT+CKK67gww8/JCoqiqSkJIYMGZK1RvjBgwe57bbbqFevHm3btqVdu3ZMnToVcL2+br/9ds4555wCuwkPHTqUN998kzPPPJN169ZlLRp12WWX0aNHDxITE0lISOD555/PuqZfv35UqFAhq2tymbZ5s1s6NFOHDtCunRtFffCgq3q69VZ3LCoKevUqeG0HY3xi06obX40aNYqDBw/y6KOPlsj7lejf+4IF8OWXbrnQBQvcuIpGjVxPJ3BjJipWhB493OA7YyKML9Oqi0gP4EXcCoBvquqoXMeb4JaLrQvsBK5X1XTv2BFgsXfqelW93NvfDJgM1AJ+Am5Q1bz9UE3E+/vf/86GDRv46quv/A7l+Bw44LrlzZ8PKSnwxhuubeKtt9x4ihYt3FxNnTpB586uikoEbrvN78iNOSZhSxwiEg28AnQD0oEFIjJdVQPXJX0WeFtV3xKRC4CngBu8Y3+qat4+pvA08LyqThaR14CbgTHh+hwmfD755BO/Qyi6zDUiYmJcb6d//cutYZ25v359V7Jo0sRVQT3xhBtcZ0wZEs42js7ASlVd7ZUIJgM9c53TEpjjPZ8b5HgO4rrmXED2crNvAVcca4DloZrOZDumv+9du+Djj13j9DnnuDaHzPXMq1Rxa1A/8AB88AGkp7v1JZo0ccfr17ekYcqkcFZVNQQ2BLxOB87Idc4ioBeuOutKoLqI1FbVHUCsiCQDGcAoVf0IqA3sUtWMgHse03DX2NhYduzYQe3atYN2FTVli6qyY8eOrDEn+dq921U9nXSSGzvRtq2rWqpUyTVm33JLdntE165uM6acCWfiCPZtnPsn3/3AyyJyE/AtsBGXKAAaq+omETkZ+EpEFgPBJtAJ+jNSRAYBgwAaN26c53h8fDzp6els27YthI9iyoLY2Fji4+Nz7ty7103f8fXXriSxcKGbimP0aNf99fHHXfvEGWe45GGMCWviSAcaBbyOBzYFnqCqm4CrAESkGtBLVXcHHENVV4vI10B7YBpQU0RivFJHnnsG3HssMBZcr6rcxytUqECzZs2O5/OZ0mjfPlixAlq1ciWJVq1gwwY3I+wZZ7h2icsuc+fGxLg2DGNMDuFMHAuAFl4vqI1AH+C6wBNEpA6wU1WPAg/helghInHAflU96J1zFvCMqqqIzAWuxrWZ9Ac+DuNnMKXdn3+6qTvmznXb/PluWvC1a13Ppv/9X9dO8de/ujYLY0yhwpY4VDVDRIYCs3Ddccer6hIRGQEkq+p04HzgKRFRXFXVHd7lpwOvi8hRXAP+qIDeWA8Ck0XkSSAFGBeuz2BKoQMHYN4815AdFeVmgX39dfc8MRHuuw/OPz+7S2zv3n5HbEypU24HAJoyZMsW1zV2+nSYPduVMhYtcg3bKSluxPbZZ+ddwtQYUyBfBgAaExaqbvnSihVdo3Zmz6ZGjdy04xdfDCef7Pa1b+82Y0yxscRhSodDh9xCRdOnwyefwMCBruG6UycYMQIuv9yVMKxrtTFhZ4nDRDZVuOkm+Ogjt5xpbKxbvKhtW3e8alXr+WRMCbPEYSLLihWuRLFyJYwZ40oQUVFw7bXw97+7pGG9n4zxlSUO47/Fi+Gdd1w11PLlbl+7dq6HVGwsTJjgb3zGmBxsPQ5T8g4dcvM/ZY7a//57twxjkybw0ktujEVqqi2LakyEshKHKTmLFrnSw6RJbmW7ceNcI/cNN0C/ftZd1phSwhKHCb99+9w4itRU14X28stdg/fFF7vj3trkxpjSwRKHKX6HDsHnn0NamptyvGpVt4DRrbdCnz5Qq5bfERpjjoMlDlN8UlNh4sTsqqjGjeHuu10p4/XX/Y7OGFNMrHHcFI/Ro90I7TFj3Ejuzz6DVatc0jDGlClW4jBFl1kVNXGiq3669FI3xiI6Gvr2taooY8o4K3GY0KWmwj33QMOGcOWVbhbanTvdsWbN3AJIljSMKfOsxGFCowpXXQUbN0LPnq5XVPfubrEjY0y5YiUOk7/vvnNTfPzxh5v6Y8oUN0X51KlwySWWNIwppyxxmLwOHXJLqJ5/vhvFvXGj29+pk1VFGWMscZhcli93y6iOHOnWtkhJgdNO8zsqY0wECWviEJEeIrJcRFaKyLAgx5uIyBwR+VlEvhaReG9/goj8ICJLvGO9A66ZKCJrRCTV2xLC+RnKnbvvhjVrYNo0ePNNqF7d74iMMREmbJXUIhINvAJ0A9KBBSIyPWDtcIBngbdV9S0RuQB4CrgB2A/cqKppItIAWCgis1R1l3fdA6r6frhiL3cyJxusWxfeeMN1q23QwN+YjDERK5wljs7ASlVdraqHgMlAz1zntATmeM/nZh5X1RWqmuY93wRsBeqGMdby6/PPoU0bGDzYvW7UyJKGMaZA4UwcDYENAa/TvX2BFgG9vOdXAtVFpHbgCSLSGagIrArY/T9eFdbzIlIp2JuLyCARSRaR5G2Zv6hNtv37YehQN3jvxBPhscf8jsgYU0qEM3EEW/xZc72+HzhPRFKA84CNQEbWDUTqA+8AA1T1qLf7IeAvQCegFvBgsDdX1bGqmqiqiXXrWmElh+XLITERXnkF7rsP5s93pQ5jjAlBODvipwONAl7HA5sCT/Cqoa4CEJFqQC9V3e29rgF8BgxX1R8DrtnsPT0oIhNwyccURe3abirzL7+ECy/0OxpjTCkTzhLHAqCFiDQTkYpAH2B64AkiUkdEMmN4CBjv7a8IfIhrOP9Prmvqe48CXAH8EsbPUHasX+96TB0+DHXquOlCLGkYY45B2BKHqmYAQ4FZwDJgqqouEZERInK5d9r5wHIRWQGcBPyPt/9a4FzgpiDdbieJyGJgMVAHeDJcn6HMSEqCtm1h/Hj4xcuzEqwm0RhjCiequZsdyp7ExERNTk72O4ySt2uXawCfNMkN6nvnHTj5ZL+jMsaUEiKyUFUTc++3keNlWZ8+MHkyjBgB33xjScMYUyxslrqy5tAhOHIEKleGUaPg4EE44wy/ozLGlCFW4ihLfv0VunSBe+91rxMSLGkYY4pdSIlDRM4WkQHe87oi0iy8YZkimzEDOnSAdevg4ov9jsYYU4YVWlUlIo8CicBpwASgAvAucFZ4QzMhmzEDrrgCWrWCTz+1KUOMMWEVShvHlUB74Cdwg/ZExKZMjRR//AE33gitW8Ps2bZehjEm7EJJHIdUVUVEAUSkaphjMkVRrZorcZx8siUNY0yJCKWNY6qIvA7UFJFbgS+BN8IblinUZ5/Biy+654mJljSMMSWm0BKHqj4rIt2APbh2jkdUdXbYIzP5+/RT6NXLjQYfMgQqVvQ7ImNMOVJg4vAWY5qlqhcBliwiwaefwlVXQbt28MUXljSMMSWuwKoqVT0C7BeRE0ooHlOQwKQxezbExfkdkTGmHAqlcfwAsFhEZgP7Mneq6l1hi8oEt2GDG9T3xRdQs6bf0RhjyqlQEsdn3mb8sns3nHCCa8+45RaoUMHviIwx5VgojeNveetjnOrtWq6qh8MblskyfTrcdBPMnAmdO1vSMMb4LpSR4+cDbwFrccvBNhKR/qr6bXhDM3z8MVxzDbRvD6eeWvj5xhhTAkKpqnoO6K6qywFE5FQgCegYzsDKvcCk8cUXrqrKGGMiQCgDACtkJg0AVV2Bm6+qUCLSQ0SWi8hKERkW5HgTEZkjIj+LyNciEh9wrL+IpHlb/4D9HUVksXfP0d4SsmXL/Plw9dVu0kJLGsaYCBNK4kgWkXEicr63vQEsLOwibwzIK8DfgJZAXxFpmeu0Z3HrircFRgBPedfWAh4FzgA6A4+KSGbf0zHAIKCFt/UI4TOULh06wCOPwKxZljSMMREnlMQxBFgC3AXcDSwFBodwXWdgpaquVtVDwGSgZ65zWgJzvOdzA45fDMxW1Z2q+jtu8GEPEakP1FDVH9Stefs2cEUIsZQOn38OmzZBTAz861+WNIwxESmUxBEDvKiqV6nqlcBoIDqE6xoCGwJep3v7Ai0CennPrwSqi0jtAq5t6D0v6J4AiMggEUkWkeRt27aFEK7Ppk2Dnj3hwQf9jsQYYwoUSuKYA1QOeF0ZN9FhYYK1PWiu1/cD54lICnAesBHIKODaUO7pdqqOVdVEVU2sW7duCOH6aNo06N0bOnWCV17xOxpjjClQKL2qYlX1j8wXqvqHiFQJ4bp0oFHA63hgU+AJqroJuApARKoBvVR1t4ikA+fnuvZr757xufbnuGepk5k0Ond2YzVq1PA7ImOMKVAoJY59ItIh84WIdAT+DOG6BUALEWnmDSDsA0wPPEFE6ohIZgwPAeO957OA7iIS5zWKd8dNtrgZ2CsiZ3q9qW4EPg4hlsh05AiMHOnWBbekYYwpJUIpcdwD/EdEMn/Z1wd6F3aRqmaIyFBcEogGxqvqEhEZASSr6nRcqeIpb5Gob4E7vGt3isgTuOQDMEJVd3rPhwATcVVmM7yt9FGF6GjXc6piRUsaxphSQ1znpEJOEqmAW4tDgF9L25QjiYmJmpyc7HcY2d5/H6ZMgUmTbFp0Y0zEEpGFqpqYe3++VVUi0klE6gF4iaID8CTwnDfOwhyLw4fd3FPp6XDokN/RGGNMkRXUxvE6cAhARM4FRuHGTewGxoY/tDJq6VLYtw/uusutF26MMaVMQW0c0QHtCr2Bsao6DZgmIqnhD62MSklxj+3b+xuHMcYco4JKHNEikplYLgS+CjgWSqO6CSYlBapUgRYt/I7EGGOOSUEJIAn4RkS247rffgcgIqfgqqvMsWjXzi3IFB3K4HtjjIk8+SYOVf0fEZmD6377hWZ3v4oC7iyJ4MqkgQP9jsAYY45LgVVOqvpjkH0rwhdOGbd/P2RkFNuYjd9/h9RUV/v100+wbJkbUxgV5bbo6JyPx7IvKgoqV4ZGjaBxY2jSxD02bGiLERpTXllbRUn67DO49lr4+Wdo0ybky1Rh8+bsBJGS4ra1a7PPiY+H1q2hUiU4etQlkMDHzOeHDuXdF+y8wMd9+2D79pwxiUCDBtmJJHMLfH3CCe48Y0zZYomjJKWkuCnTC1gG9uhRWL06Z4JISYGtW7PPOfVUN0vJ4MGuc1b79hDueRz374cNG2D9eretW5f9fMEC+OCDvMNSqlcvOLHUq2fjH40pjUJZc3woMMlbF8Mcj5QUaNnSFQtwYwGXLs2ZIFJTYe9ed3pMjCtFXHppdoJo1859IZe0KlXgtNPcFszRo/Dbb8ETy/r1MG8e7NiR97rKlSEuDmrWPLbNqsuMKXmhlEgretIAABxvSURBVDjqAQtE5CfcJISzNJR5SkxeKSn8edHfeexBmDMHFi/O/pVepQokJMCNN2YniVatsnJMxIuKgvr13XbGGcHP+eOP7FLLunWuFLVrV87tt99g+fLs10eOFPy+VavmTSZVqriEVBxbpUpW3WZMbqHOVSW4GWoHAInAVGCcqq4Kb3jFIyLmqtq8mTUN/spVDeeRuvFELrzQrRCbmSRatLAeurmpuvaVzCTy++95E03u7fffXbXan3/m3ApLQPkRgdhYN8i/WTP393TqqTkfbX5KU1blN1dVSG0cqqoisgXYgltoKQ54X0Rmq+r/K95Qy6ZZ/1eNvlWWcXRPBT791FU/mYKJuC/satVc4//xOHw4bzIpyrZnj2t7+vZbNzdloBNPzE4igQnllFNc6ceYsiaUNo67gP7AduBN4AFVPeyto5EGWOIowNGjMGoUDB9endatXSPyKaf4HVX5U6GC24qjdPDnn7BqFaxYAWlpbluxAmbMgAkTcp4bH583obRoASefXHqqIY3JLZQSRx3gKlVdF7hTVY+KyGXhCats2LMH+veHjz6Cvhdt440X9lH1lKZ+h2WOU+XKrtNC69Z5j+3dm51MMhNKWppb6DGwc0BUlOthllkyCdyaNXPVY8ZEqlASx+dA5mSHiEh1oKWqzlPVZWGLrJRbuhSuvNL9Mn3+ebj7xTOQxxNh6lS/QzNhVL26a7vq0CHvsZ078yaUtDTX42x3wCQ+Im7AZe6EcsoprqRStWrJfR5jggklcYzBrcWRaV+QfUGJSA/gRdwKgG+q6qhcxxsDbwE1vXOGqernItIPeCDg1LZAB1VNFZGvcdOgZC5f211VA0Y5+G/aNLfkRpUqrvfUee12wb1rYNCtfodmfFSrlutxlrvXmapLKitX5t0++CDv4MsGDVwSad48b2KxhnpTEkJJHBLY/darogqlbSQaeAXoBqTjuvROV9WlAacNB6aq6hgRaYkr3TRV1UnAJO8+bYCPVTVwKvd+qhpBS/o5GRnw8MPwzDNw5pnwn/94jbpfe6HbVOomCBGoXdttwboy797tSq65k8rMmW5GgUB167oEct55cMcdx9+pwJhgQkkcq70G8jHe69uB1SFc1xlYqaqrAURkMtATCEwcCmT+RjoB2ERefXEz9Ua0bdugb19Xwhg8GF54IaDx09bgMMfhhBPyr/7aty87qWQ+Ll/ufrw8+yz07g333gsdO5Z83KbsCiVxDAZG40oHCswBBoVwXUNgQ8DrdCD376nHgC9E5E6gKnBRkPv0xiWcQBNE5AgwDXgy2IBEERmUGWfjxo1DCPfYJSdDr15u8Nq4cUEmwE1JcSPjTjoprHGY8qdqVWjb1m2B1q6Fl16CN95w3YfPOw/uuw8uu8w1zBtzPAr9J6SqW1W1j6qeqKonqep1IbYpBBtvm/sLvi8wUVXjgUuAd7xuvu4GImcA+1X1l4Br+qlqG+Acb7shn7jHqmqiqibWDeNETuPHw9lnu+fff5/PrOkjR8L774ctBmNya9oUnnvOLW3/73+7RNKzp5sy5tVXXUnFmGNV6MhxEYkFbgZaAVmdBFW1wIUlRKQL8JiqXuy9fsi77qmAc5YAPVR1g/d6NXBmZmISkeeBbao6Mp/3uAlIVNWhBcUSjpHjBw/C3XfD66/DhRfC5MlQp06xvoUxxSYjAz780CWTefPc/GC33QZDh7op8kvaunUwe7bbUlLc/51GjdwWH5/9vFEjV1C3UpI/jmfk+DvAr8DFwAigHxBKN9wFQAsRaQZsBPoA1+U6Zz1uWdqJInI6LjFt8wKOAq4Bzg34EDFATVXdLiIVgMuAL0OIpVilp8PVV7v/gA8+CE8+6SYkDGrVKvj0U7juuvBPYWtMPmJi4Jpr3PbDD64UktkO0qePawcJ1oZSXHbvhrlzs5NFWprb36CB60iya5dLINOnw4EDeWNv2DBnMsmdYOrWtTnFSlIoJY4UVW0vIj+ralvvC3uWql5Q6M1FLgFewHW1He+tKjgCSFbV6V5PqjeAarhqrP+nql94154PjFLVMwPuVxX4Fqjg3fNL4D5VLXAmouIscXzzjVtSY/9+mDjRtW0UaOxY99Nu1SrXCd+YCLFmDYweDW++6SagPP981w5y6aXH/wv/8GH3wyozUcyf7+YLq1rVvU+3bm47/fScX/iZXZM3bMi5pafnfJ57Cv9KlVwiCUwmHTvCVVdZQjke+ZU4Qkkc81W1s4h8i+tRtQWYr6ql5luwOBKHqusp9cADrv/8hx+6GdILNWQIJCW52ffsX7CJQLt3u04dL77oZi5u0cKVQG68MfTBhqquN1dmovj6azeKPioKOnXKThRnnnn8a7AcPep6MeZOKIHbxo0uUZ17Lrz2mktQpujySxyoaoEbcAtuUsNzcd1wtwK3FXZdJG0dO3bU4/HHH6p9+qiC6hVXqO7eXYSLzzhD9bzzjuv9jSkJhw+rTpmi2rmz+7deq5bqP/+punFj8PO3blV97z3VAQNU4+PdNaDavLnq4MGq06ap7txZsp8hU0aG6htvqMbFqVaooPrww6r79/sTS2mGqx3KmxeC7cw66HpdXVvQOaVhO57EkZam2rq1qojqyJGqR44U4eKMDNXKlVXvueeY39+Yknb0qOr//Z9qr16qUVHui/eGG1Tnz1f94gvVBx5QTUjIThRxce7c119XXb3a7+hz+u03F3tmQps1y++IgjtyxP25R5r8EkcoVVXfquq5BZ4U4Y61quqzz6BfP7dOxnvvwcUXF/EGK1e6/o8TJrhyvzGlzOrVrh1k3DjXDgJuluG//jW7+qljx8hfS+arr1yt8YoVrjPA88+7pYv9tn6966jw5puui3RsrNsqVz6+x8DnXbse+6qhx9PG8S/cvFBTcPNUAaCqO/O9KMIcS+JQhcsvd3WoH3zgZiw9Jvv2ubYNW5jBlGK7drk52OrXd+0G1ar5HVHRHTwITz/thlXFxrrH227zJ+ktXux6tSUlua+HPn1c35kDB9y0/UV9PHgw//f69df8l3wuzPEkjjVBdquWg8bx3btdQ17lymEIyhjji7Q0V/qYMwc6d3ZjsRISwv++qm4hsGeegc8/dx0PBg1yHREaNTq+ex896pJHsMTSqtWxT9N/zImjLPBt6dhhw9yiC0OGlPx7G2Pypeqqn++7z62Tcvfd8Pjj4SlJHT3q1uR55hnXRbluXfd+Q4a4GZMjWX6Jo9De2iJyY7AtPGGWIapuDEdqauHnGmNKlIhrv/z1V7jlFtfO0LIlfPxx8b3HwYOu7eL00914r+3bYcwYN2r+4YcjP2kUJJRhPp0CtnNwExNeHsaYyob1693YDZsR15iIFRfnxnn8979QsyZccYXb1q8/9nvu3u3aUpo2hVtvdaWYKVPcOJfBg8tG1XehU46o6p2Br0XkBNw0JKYgNpW6MaVGly6wcKEb5PvYY6708fjjrkop3+mEctm0yV3/2mtu8GO3bvDuu3DBBWVv7O+xTCywH2hR3IGUOSkpbthsmzZ+R2KMCUGFCm5miKVLXRfW+++HxETXLlGQzOquZs3cJJKXXgo//QRffOEmQC1rSQNCa+P4RESme9unwHKgGGsCy6ijR11nd+uGa0yp0qSJm2wxc9neLl3g9ttdl+RAP/wAV17pSieTJrlqqbQ018W2rFc0hNId97yAlxnAOlVND2tUxcy3XlXGmFJt71545BE3CPLEE93AwerVXRvGd9+5Bu6hQ91WFie/Pp5p1dcDm1X1gHejyiLSVFXXFnOMxhgTUapXd8nihhvcYMG+fd3+xo1de8bNN5fOwZDHK5Q2jv8ARwNeH/H2mfx89ZVby3NZKMuWGGMiXYcO8OOP8M47bvzHypWu4bw8Jg0IrcQRo6pZs9+r6iEROc6Jkcu4BQvcnAK2xrgxZUZ0NFx/vd9RRIZQShzbRCRr3IaI9AS2hy+kMiAlxbWwleYRPsYYk49QEsdg4J8isl5E1gMPAreFcnMR6SEiy0VkpYgMC3K8sYjMFZEUEfnZWzEQEWkqIn+KSKq3vRZwTUcRWezdc7RIBHZ2S0kp+90qjDHlVigDAFcBZ4pINVwvrL2h3FhEooFXgG5AOrBARKar6tKA04YDU1V1jLeM7OdAU+/YKlUNNvXYGGAQ8KN3fg9gRigxlYg//nB98vr18zsSY4wJi1DGcYwUkZqq+oeq7hWROBF5MoR7dwZWqupqr41kMtAz1zkK1PCenwBsKiSW+kANVf3BW2TkbeCKEGIpOXv3wnXXwXnnFX6uMcaUQqFUVf1NVbOGvqjq78AlIVzXENgQ8Drd2xfoMeB6EUnHlR4Cpzdp5lVhfSMi5wTcM3AMSbB7AiAig0QkWUSSt23bFkK4xaR+fTfPgCUOY0wZFUriiBaRSpkvRKQyUKmA87NODbIv92jDvsBEVY3HJaN3RCQK2Aw0VtX2wH3AeyJSI8R7up2qY1U1UVUT65bkyJw9e9zMuMYYU0aF0h33XWCOiEzAfUkPxFURFSYdCFyeJJ68VVE349ooUNUfRCQWqKOqW4GD3v6FIrIKONW7Z3wh9/TX+ee7pbzef9/vSIwxJiwKLXGo6jPAk8DpQCvgCVV9OoR7LwBaiEgzb9xHH2B6rnPWAxcCiMjpQCyu+29dr3EdETkZN6nialXdDOwVkTO93lQ3EknzZh06BL/8As2b+x2JMcaETUgTBqvqTGAmgIicJSKvqOodhVyTISJDgVlANDBeVZeIyAggWVWnA/8A3hCRe3GlmZtUVUXkXGCEiGTgRqoPDljjfAgwEaiM600VOT2qli6Fw4etK64xpkwLKXGISAKuPaI3sAb4IJTrVPVzXKN34L5HAp4vBc4Kct00YFo+90wGWofy/iXO1uAwxpQD+SYOETkVV73UF9gBTMGN4+haQrGVPikpbgX6FrZciTGm7CqoxPEr8B3wd1VdCeBVKZn8/P3vLmlEHcv6WMYYUzoUlDh64Uocc0VkJm4AX+RN7xFJunVzmzHGlGH5/jRW1Q9VtTfwF+Br4F7gJBEZIyLdSyi+0mPnTkhOdj2rjDGmDAulO+4+VZ2kqpfhxk2kAnkmLCz3Zs+GTp1gyRK/IzHGmLAqUmW8qu5U1ddV9YJwBVRqpaS41e5btfI7EmOMCStrxS0uKSkuaVS0Na6MMWWbJY7ioGprcBhjyg1LHMVh0ybYts0ShzGmXAhp5LgpRO3aMGeODfwzxpQLljiKQ2wsXGD9BYwx5YNVVRWHKVNg7ly/ozDGmBJhiaM4DBsGr73mdxTGGFMiLHEcr99/h7VrrWHcGFNuWOI4Xqmp7tEShzGmnLDEcbxsDQ5jTDkT1sQhIj1EZLmIrBSRPPNbiUhjEZkrIiki8rOIXOLt7yYiC0Vksfd4QcA1X3v3TPW2E8P5GQq1eDE0aAAn+huGMcaUlLB1x/XWDH8F6AakAwtEZLq36l+m4cBUVR0jIi1xqwU2Bbbj1gHZJCKtccvPNgy4rp+3EqD/3nwTNm/2OwpjjCkx4SxxdAZWqupqVT2EW8+jZ65zFKjhPT8B2ASgqimqusnbvwSIFZFKYYz12EVHQ3y831EYY0yJCWfiaAhsCHidTs5SA8BjwPUiko4rbdwZ5D69gBRVPRiwb4JXTfUvEQm6uJSIDBKRZBFJ3rZt2zF/iAItWQJDhrheVcYYU06EM3EE+0LXXK/7AhNVNR64BHhHRLJiEpFWwNPAbQHX9FPVNsA53nZDsDdX1bGqmqiqiXXr1j2Oj1GA776z8RvGmHInnIkjHWgU8DoeryoqwM3AVABV/QGIBeoAiEg88CFwo6quyrxAVTd6j3uB93BVYv5ISYG4OGjSxLcQjDGmpIUzcSwAWohIMxGpiFu/fHquc9YDFwKIyOm4xLFNRGoCnwEPqer/ZZ4sIjEikplYKgCXAb+E8TMULCUFEhIgeG2ZMcaUSWFLHKqaAQzF9Yhahus9tURERojI5d5p/wBuFZFFQBJwk6qqd90pwL9ydbutBMwSkZ9xS9huBN4I12coUEaG64pr4zeMMeVMWGfHVdXPcY3egfseCXi+FDgryHVPAk/mc9uOxRnjMduyBerVgw4d/I7EGGNKlE2rfqzi42HNGrf6nzHGlCM25cjxsvYNY0w5Y4njWF1/vZtO3RhjyhlLHMdCFT77DHbt8jsSY4wpcZY4jsXatS5pWI8qY0w5ZInjWNhU6saYcswSx7FISXGTG7Zp43ckxhhT4ixxHIuGDaFPH6hc2e9IjDGmxFniOBaDB8O77/odhTHG+MISR1FlZLjNGGPKKUscRTVnDtSoAcmRsQChMcaUNEscRZWSAn/+Caec4nckxhjjC0scRZWSAk2bQs2afkdijDG+sMRRVCkpNn7DGFOuWeIoir17IS3NEocxplyzadWLIiMDnngCevTwOxJjjPFNWEscItJDRJaLyEoRyTOVrIg0FpG5IpIiIj+LyCUBxx7yrlsuIheHes+wiouD4cMhMbFE39YYYyJJ2BKHiEQDrwB/A1oCfUWkZa7ThuOWlG2PW5P8Ve/alt7rVkAP4FURiQ7xnuGzbBns2FFib2eMMZEonCWOzsBKVV2tqoeAyUDPXOcoUMN7fgKwyXveE5isqgdVdQ2w0rtfKPcMn759oV+/Ens7Y4yJROFMHA2BDQGv0719gR4DrheRdNza5HcWcm0o9wRARAaJSLKIJG/btu1YP0O2gwdhyRJrGDfGlHvhTBzB1lTNvUB3X2CiqsYDlwDviEhUAdeGck+3U3WsqiaqamLdunWLEHY+lixxjeOWOIwx5Vw4e1WlA40CXseTXRWV6WZcGwaq+oOIxAJ1Crm2sHuGh63BYYwxQHhLHAuAFiLSTEQq4hq7p+c6Zz1wIYCInA7EAtu88/qISCURaQa0AOaHeM/wSEmB6tWhefMSeTtjjIlUYStxqGqGiAwFZgHRwHhVXSIiI4BkVZ0O/AN4Q0TuxVU53aSqCiwRkanAUiADuENVjwAEu2e4PkMOQ4dC9+4QZWMmjTHlm7jv6bItMTFRk202W2OMKRIRWaiqeQau2c/nUGzeDO+8Y2M4jDEGSxyh+eYbuPFG2LCh8HONMaaMs8QRipQUqFABWpbcIHVjjIlUljhCkZICrVtDxYp+R2KMMb6zxFEYVVuDwxhjAljiKMymTbB9uyUOY4zx2HochWnQADZuhNhYvyMxxpiIYImjMCIueRhjjAGsqqpw//43TJjgdxTGGBMxLHEU5sUX4Ysv/I7CGGMihiWOguzYAevXW8O4McYEsMRRkNRU92iJwxhjsljiKIitwWGMMXlY4ijIjh1w8slQp47fkRhjTMSwxFGQp56CFSv8jsIYYyKKJY7CREf7HYExxkSUsCYOEekhIstFZKWIDAty/HkRSfW2FSKyy9vfNWB/qogcEJErvGMTRWRNwLGEcH4GY4wxOYVt5LiIRAOvAN2AdGCBiExX1aWZ56jqvQHn3wm09/bPBRK8/bWAlUDgYIoHVPX9cMVujDEmf+EscXQGVqrqalU9BEwGehZwfl8gKcj+q4EZqro/DDEaY4wponAmjoZA4JJ56d6+PESkCdAM+CrI4T7kTSj/IyI/e1VdlfK55yARSRaR5G3bthU9emOMMUGFM3FIkH2az7l9gPdV9UiOG4jUB9oAswJ2PwT8BegE1AIeDHZDVR2rqomqmli3bt2ixm6MMSYf4Uwc6UCjgNfxwKZ8zg1WqgC4FvhQVQ9n7lDVzeocBCbgqsSMMcaUkHAmjgVACxFpJiIVcclheu6TROQ0IA74Icg98rR7eKUQRESAK4BfijluY4wxBQhbrypVzRCRobhqpmhgvKouEZERQLKqZiaRvsBkVc1RjSUiTXEllm9y3XqSiNTFVYWlAoPD9RmMMcbkJbm+r8skEdkGrPM7jlzqANv9DiJEpSlWKF3xlqZYoXTFW5pihciMt4mq5mkkLheJIxKJSLKqJvodRyhKU6xQuuItTbFC6Yq3NMUKpStem3LEGGNMkVjiMMYYUySWOPwz1u8AiqA0xQqlK97SFCuUrnhLU6xQiuK1Ng5jjDFFYiUOY4wxRWKJwxhjTJFY4ihBItJIROaKyDIRWSIid/sdUyhEJFpEUkTkU79jKYiI1BSR90XkV+/PuIvfMRVERO71/h38IiJJIhLrd0yBRGS8iGwVkV8C9tUSkdkikuY9xvkZY6Z8Yv1f79/CzyLyoYjU9DPGTMFiDTh2v4ioiET0etWWOEpWBvAPVT0dOBO4Q0Ra+hxTKO4GlvkdRAheBGaq6l+AdkRwzCLSELgLSFTV1rjZFfr4G1UeE4EeufYNA+aoagtgjvc6Ekwkb6yzgdaq2hZYgZsgNRJMJG+siEgj3PpF60s6oKKyxFGCvAkaf/Ke78V9sQWdaj5SiEg8cCnwpt+xFEREagDnAuMAVPWQqu7yN6pCxQCVRSQGqEL+k4D6QlW/BXbm2t0TeMt7/hZuvjjfBYtVVb9Q1Qzv5Y+4iVZ9l8+fK8DzwP8j/1nEI4YlDp94c3G1B+b5G0mhXsD9Yz7qdyCFOBnYBkzwqtXeFJGqfgeVH1XdCDyL+3W5Gditql8UfFVEOElVN4P7IQSc6HM8oRoIzPA7iPyIyOXARlVd5HcsobDE4QMRqQZMA+5R1T1+x5MfEbkM2KqqC/2OJQQxQAdgjKq2B/YROdUoeXhtAz1xC5g1AKqKyPX+RlU2icjDuGriSX7HEoyIVAEeBh7xO5ZQWeIoYSJSAZc0JqnqB37HU4izgMtFZC1u6d8LRORdf0PKVzqQrqqZJbj3cYkkUl0ErFHVbd56Mx8Af/U5plD8FrC0QX1gq8/xFEhE+gOXAf1yz8AdQZrjfkAs8v6vxQM/iUg9X6MqgCWOEuStITIOWKaq//Y7nsKo6kOqGq+qTXENt1+pakT+KlbVLcAGb30XgAuBpT6GVJj1wJkiUsX7d3EhEdyYH2A60N973h/42MdYCiQiPXArhF6uqvv9jic/qrpYVU9U1abe/7V0oIP3bzoiWeIoWWcBN+B+uad62yV+B1WG3Ilbr+VnIAEY6XM8+fJKRu8DPwGLcf8XI2rKCRFJwi2wdpqIpIvIzcAooJuIpOF6AI3yM8ZM+cT6MlAdmO39X3vN1yA9+cRaqtiUI8YYY4rEShzGGGOKxBKHMcaYIrHEYYwxpkgscRhjjCkSSxzGGGOKxBKHMcVARI4EdLFOFZFiG7UuIk2DzaRqjF9i/A7AmDLiT1VN8DsIY0qClTiMCSMRWSsiT4vIfG87xdvfRETmeGtFzBGRxt7+k7y1IxZ5W+Y0JNEi8oa3fscXIlLZtw9lyj1LHMYUj8q5qqp6Bxzbo6qdcSOZX/D2vQy87a0VMQkY7e0fDXyjqu1wc20t8fa3AF5R1VbALqBXmD+PMfmykePGFAMR+UNVqwXZvxa4QFVXexNcblHV2iKyHaivqoe9/ZtVtY6IbAPiVfVgwD2aArO9xZMQkQeBCqr6ZPg/mTF5WYnDmPDTfJ7nd04wBwOeH8HaJ42PLHEYE369Ax5/8J7/l+ylYvsB33vP5wBDIGut9xolFaQxobJfLcYUj8oikhrweqaqZnbJrSQi83A/1Pp6++4CxovIA7iVCwd4++8Gxnozph7BJZHNYY/emCKwNg5jwshr40hU1e1+x2JMcbGqKmOMMUViJQ5jjDFFYiUOY4wxRWKJwxhjTJFY4jDGGFMkljiMMcYUiSUOY4wxRfL/AYSoZXgbtb/PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and test accuracy histories\n",
    "training_accuracy = history.history[\"accuracy\"]\n",
    "test_accuracy = history.history[\"val_accuracy\"]\n",
    "plt.plot(epoch_count, training_accuracy, \"r--\")\n",
    "plt.plot(epoch_count, test_accuracy, \"b-\")\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.legend([\"Training Accuracy\", \"Test Accuracy\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.8 Reducing Overfitting with Weight Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         kernel_regularizer=regularizers.l2(0.01),\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         kernel_regularizer=regularizers.l2(0.01),\n",
    "                         activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.9 Reducing Overfitting with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=2),\n",
    "             ModelCheckpoint(filepath=\"best_model.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             save_best_only=True)]\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=20, # Number of epochs\n",
    "                      callbacks=callbacks, # Early stopping\n",
    "                      verbose=0, # Print description after each epoch\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.10 Reducing Overfitting with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add a dropout layer for input layer\n",
    "network.add(layers.Dropout(0.2, input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network.add(layers.Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.11 Saving Model Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Convert movie review data to a one-hot encoded feature matrix\n",
    "tokenizer = Tokenizer(num_words=number_of_features)\n",
    "features_train = tokenizer.sequences_to_matrix(data_train, mode=\"binary\")\n",
    "features_test = tokenizer.sequences_to_matrix(data_test, mode=\"binary\")\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16,\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(number_of_features,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "checkpoint = [ModelCheckpoint(filepath=\"models.hdf5\")]\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target vector\n",
    "                      epochs=3, # Number of epochs\n",
    "                      callbacks=checkpoint, # Checkpoint\n",
    "                      verbose=0, # No output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.12 k-Fold Cross-Validating Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8911218 , 0.88598859, 0.85058504])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of features\n",
    "number_of_features = 100\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = number_of_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.5, .5],\n",
    "                                       random_state = 0)\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network():\n",
    "\n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(\n",
    "        number_of_features,)))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                    optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                    metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network,\n",
    "                                 epochs=10,\n",
    "                                 batch_size=100,\n",
    "                                 verbose=0)\n",
    "\n",
    "# Evaluate neural network using three-fold cross-validation\n",
    "cross_val_score(neural_network, features, target, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.13 Tuning Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of features\n",
    "number_of_features = 100\n",
    "\n",
    "# Generate features matrix and target vector\n",
    "features, target = make_classification(n_samples = 10000,\n",
    "                                       n_features = number_of_features,\n",
    "                                       n_informative = 3,\n",
    "                                       n_redundant = 0,\n",
    "                                       n_classes = 2,\n",
    "                                       weights = [.5, .5],\n",
    "                                       random_state = 0)\n",
    "\n",
    "# Create function returning a compiled network\n",
    "def create_network(optimizer=\"rmsprop\"):\n",
    "\n",
    "    # Start neural network\n",
    "    network = models.Sequential()\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16,\n",
    "                             activation=\"relu\",\n",
    "                             input_shape=(number_of_features,)))\n",
    "\n",
    "    # Add fully connected layer with a ReLU activation function\n",
    "    network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "    # Add fully connected layer with a sigmoid activation function\n",
    "    network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile neural network\n",
    "    network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                    optimizer=optimizer, # Optimizer\n",
    "                    metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "neural_network = KerasClassifier(build_fn=create_network, verbose=0)\n",
    "\n",
    "# Create hyperparameter space\n",
    "epochs = [5, 10]\n",
    "batches = [5, 10, 100]\n",
    "optimizers = [\"rmsprop\", \"adam\"]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "\n",
    "# Create grid search\n",
    "grid = GridSearchCV(estimator=neural_network, param_grid=hyperparameters)\n",
    "\n",
    "# Fit grid search\n",
    "grid_result = grid.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 5, 'epochs': 5, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View hyperparameters of best neural network\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.14 Visualizing Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4b775b7a2dd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Visualize network architecture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dot\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"svg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create'"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\", input_shape=(10,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(layers.Dense(units=16, activation=\"relu\"))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Visualize network architecture\n",
    "SVG(model_to_dot(network, show_shapes=True).create(prog=\"dot\", format=\"svg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.15 Classifying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 29s 3us/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential_75/max_pooling2d/MaxPool (defined at <ipython-input-20-bbe95ad01f8c>:76) ]] [Op:__inference_train_function_886419]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bbe95ad01f8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Don't print description after each epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Number of observations per batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             validation_data=(features_test, target_test)) # Data for evaluation\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Default MaxPoolingOp only supports NHWC on device type CPU\n\t [[node sequential_75/max_pooling2d/MaxPool (defined at <ipython-input-20-bbe95ad01f8c>:76) ]] [Op:__inference_train_function_886419]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format(\"channels_first\")\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28\n",
    "\n",
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\n",
    "\n",
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)\n",
    "\n",
    "# Reshape test image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)\n",
    "\n",
    "# Rescale pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255\n",
    "\n",
    "# One-hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]\n",
    "\n",
    "# Start neural network\n",
    "network = Sequential()\n",
    "\n",
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "network.add(Conv2D(filters=64,\n",
    "                   kernel_size=(5, 5),\n",
    "                   input_shape=(channels, width, height),\n",
    "                   activation='relu'))\n",
    "\n",
    "# Add max pooling layer with a 2x2 window\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Add layer to flatten input\n",
    "network.add(Flatten())\n",
    "\n",
    "# # Add fully connected layer of 128 units with a ReLU activation function\n",
    "network.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))\n",
    "\n",
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "network.fit(features_train, # Features\n",
    "            target_train, # Target\n",
    "            epochs=2, # Number of epochs\n",
    "            verbose=0, # Don't print description after each epoch\n",
    "            batch_size=1000, # Number of observations per batch\n",
    "            validation_data=(features_test, target_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.16 Improving Performance with Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create image augmentation\n",
    "augmentation = ImageDataGenerator(featurewise_center=True, # Apply ZCA whitening\n",
    "                                  zoom_range=0.3, # Randomly zoom in on images\n",
    "                                  width_shift_range=0.2, # Randomly shift images\n",
    "                                  horizontal_flip=True, # Randomly flip images\n",
    "                                  rotation_range=90) # Randomly rotate\n",
    "\n",
    "# Process all images from the directory 'raw/images'\n",
    "augment_images = augmentation.flow_from_directory(\"raw/images\", # Image folder\n",
    "                                                  batch_size=32, # Batch size\n",
    "                                                  class_mode=\"binary\", # Classes\n",
    "                                                  save_to_dir=\"processed/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, since augment_images is a generator, when training our neural network we will have to use fit_generator \n",
    "# instead of fit. For example:\n",
    "\n",
    "# Train neural network\n",
    "network.fit_generator(augment_images,\n",
    "                      #Number of times to call the generator for each epoch\n",
    "                      steps_per_epoch=2000,\n",
    "                      # Number of epochs\n",
    "                      epochs=5,\n",
    "                      # Test data generator\n",
    "                      validation_data=augment_images_test,\n",
    "                      # Number of items to call the generator\n",
    "                      # for each test epoch\n",
    "                      validation_steps=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.17 Classifying Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1811\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1812\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-449b482d44e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Add a long short-term memory layer with 128 units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Add fully connected layer with a sigmoid activation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    219\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m--> 926\u001b[1;33m                                                 input_list)\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m               \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1181\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         (last_output, outputs, new_h, new_c,\n\u001b[1;32m-> 1183\u001b[1;33m          runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m       \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   1556\u001b[0m   \u001b[1;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1557\u001b[0m   last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(\n\u001b[1;32m-> 1558\u001b[1;33m       **params)\n\u001b[0m\u001b[0;32m   1559\u001b[0m   \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2828\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   1313\u001b[0m       input_length=(sequence_lengths\n\u001b[0;32m   1314\u001b[0m                     if sequence_lengths is not None else timesteps),\n\u001b[1;32m-> 1315\u001b[1;33m       zero_output_for_mask=zero_output_for_mask)\n\u001b[0m\u001b[0;32m   1316\u001b[0m   return (last_output, outputs, new_states[0], new_states[1],\n\u001b[0;32m   1317\u001b[0m           _runtime(_RUNTIME_CPU))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4212\u001b[0m     \u001b[1;31m# the value is discarded.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4213\u001b[0m     output_time_zero, _ = step_function(\n\u001b[1;32m-> 4214\u001b[1;33m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0m\u001b[0;32m   4215\u001b[0m     output_ta = tuple(\n\u001b[0;32m   4216\u001b[0m         tensor_array_ops.TensorArray(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_tm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecurrent_kernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1293\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[0mz0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(x, bias, data_format)\u001b[0m\n\u001b[0;32m   5770\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5771\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5772\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5773\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5774\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3366\u001b[0m       return gen_nn_ops.bias_add(\n\u001b[1;32m-> 3367\u001b[1;33m           value, bias, data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   3368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[1;32m--> 694\u001b[1;33m         \"BiasAdd\", value=value, bias=bias, data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    695\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    591\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    592\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3483\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3484\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3485\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3486\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3487\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1973\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1974\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 1975\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   1976\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1977\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1813\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1815\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1817\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=\"NCHW\"](add, bias)' with input shapes: [?,512], [512]."
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set the number of features we want\n",
    "number_of_features = 1000\n",
    "\n",
    "# Load data and target vector from movie review data\n",
    "(data_train, target_train), (data_test, target_test) = imdb.load_data(\n",
    "    num_words=number_of_features)\n",
    "\n",
    "# Use padding or truncation to make each observation have 400 features\n",
    "features_train = sequence.pad_sequences(data_train, maxlen=400)\n",
    "features_test = sequence.pad_sequences(data_test, maxlen=400)\n",
    "\n",
    "# Start neural network\n",
    "network = models.Sequential()\n",
    "\n",
    "# Add an embedding layer\n",
    "network.add(layers.Embedding(input_dim=number_of_features, output_dim=128))\n",
    "\n",
    "# Add a long short-term memory layer with 128 units\n",
    "network.add(layers.LSTM(units=128))\n",
    "\n",
    "# Add fully connected layer with a sigmoid activation function\n",
    "network.add(layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile neural network\n",
    "network.compile(loss=\"binary_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"Adam\", # Adam optimization\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric\n",
    "\n",
    "# Train neural network\n",
    "history = network.fit(features_train, # Features\n",
    "                      target_train, # Target\n",
    "                      epochs=3, # Number of epochs\n",
    "                      verbose=0, # Do not print description after each epoch\n",
    "                      batch_size=1000, # Number of observations per batch\n",
    "                      validation_data=(features_test, target_test)) # Test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

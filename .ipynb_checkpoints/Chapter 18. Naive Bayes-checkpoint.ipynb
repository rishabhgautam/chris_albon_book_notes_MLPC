{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.1 Training a Classifier for Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create Gaussian Naive Bayes object\n",
    "classifer = GaussianNB()\n",
    "\n",
    "# Train model\n",
    "model = classifer.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.2 Training a Classifier for Discrete and Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Brazil is best',\n",
    "                      'Germany beats both'])\n",
    "\n",
    "# Create bag of words\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# Create feature matrix\n",
    "features = bag_of_words.toarray()\n",
    "\n",
    "# Create target vector\n",
    "target = np.array([0,0,1])\n",
    "\n",
    "# Create multinomial naive Bayes object with prior probabilities of each class\n",
    "classifer = MultinomialNB(class_prior=[0.25, 0.5])\n",
    "\n",
    "# Train model\n",
    "model = classifer.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.3 Training a Naive Bayes Classifier for Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Create three binary features\n",
    "features = np.random.randint(2, size=(100, 3))\n",
    "\n",
    "# Create a binary target vector\n",
    "target = np.random.randint(2, size=(100, 1)).ravel()\n",
    "\n",
    "# Create Bernoulli Naive Bayes object with prior probabilities of each class\n",
    "classifer = BernoulliNB(class_prior=[0.25, 0.5])\n",
    "\n",
    "# Train model\n",
    "model = classifer.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.4 Calibrating Predicted Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31859969, 0.63663466, 0.04476565]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# Create Gaussian Naive Bayes object\n",
    "classifer = GaussianNB()\n",
    "\n",
    "# Create calibrated cross-validation with sigmoid calibration\n",
    "classifer_sigmoid = CalibratedClassifierCV(classifer, cv=2, method='sigmoid')\n",
    "\n",
    "# Calibrate probabilities\n",
    "classifer_sigmoid.fit(features, target)\n",
    "\n",
    "# Create new observation\n",
    "new_observation = [[ 2.6,  2.6,  2.6,  0.4]]\n",
    "\n",
    "# View calibrated probabilities\n",
    "classifer_sigmoid.predict_proba(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CalibratedClassifierCV offers two calibration methods—Platt’s sigmoid model and isotonic regression—defined by the \n",
    "# method paramenter. While we don’t have the space to go into the specifics, because isotonic regression is nonparametric\n",
    "# it tends to overfit when sample sizes are very small (e.g., 100 observations). In our solution we used the Iris dataset \n",
    "# with 150 observations and therefore used the Platt’s sigmoid model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
